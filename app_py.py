# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18-Pv0tCYAIevSu1BZkKnyOwRuGpnE8LN
"""

!pip install pytesseract pdf2image transformers openai streamlit localtunnel PyMuPDF pillow langdetect
!apt-get install tesseract-ocr
!apt-get install poppler-utils
!apt-get install tesseract-ocr-eng tesseract-ocr-spa tesseract-ocr-fra tesseract-ocr-hin

!pip install pdf2image
!pip install langdetect

import os
import fitz  # PyMuPDF
import pytesseract
from transformers import pipeline
from langdetect import detect
import openai
import streamlit as st
from pdf2image import convert_from_path
from io import BytesIO
from zipfile import ZipFile

# Set up Tesseract Path
pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'

# OpenAI API Key
openai.api_key = "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"  # Replace with your OpenAI API key

# Supported languages
LANGUAGES = {
    "en": "eng",
    "es": "spa",
    "fr": "fra",
    "hi": "hin",
}

# Helper Function: Detect Language
def detect_language(text):
    try:
        lang_code = detect(text)
        return LANGUAGES.get(lang_code, "eng")  # Default to English if unsupported
    except Exception as e:
        return "eng"  # Default to English

# Helper Function: Extract Text from PDF
def extract_text_from_pdf(pdf_path):
    try:
        doc = fitz.open(pdf_path)  # Open PDF file
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        if not text.strip():  # If no text is extracted, use OCR
            images = convert_from_path(pdf_path)
            for image in images:
                # Use detected language for OCR
                text += pytesseract.image_to_string(image, lang="eng")
        return text
    except Exception as e:
        return f"Error reading PDF: {e}"

# Helper Function: Classify Document
def classify_document(text):
    try:
        classifier = pipeline("text-classification", model="distilbert-base-uncased-finetuned-sst-2-english")
        result = classifier(text[:512])  # Limit input to 512 tokens
        return result[0]['label']
    except Exception as e:
        return f"Error in classification: {e}"

# Helper Function: Summarize Text
def summarize_text(text):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": text}]
        )
        return response['choices'][0]['message']['content']
    except Exception as e:
        return f"Error in summarization: {e}"

# Streamlit App
def main():
    st.title("Enhanced Document Processing Tool")
    st.markdown("Upload financial documents for **multilingual OCR**, **classification**, and **summarization**.")

    # Multiple File Uploads
    uploaded_files = st.file_uploader("Upload PDF files (single or multiple)", type=["pdf"], accept_multiple_files=True)

    if uploaded_files:
        results = []
        for uploaded_file in uploaded_files:
            with open(uploaded_file.name, "wb") as f:
                f.write(uploaded_file.getbuffer())

            # Step 1: Extract Text
            st.subheader(f"Processing: {uploaded_file.name}")
            extracted_text = extract_text_from_pdf(uploaded_file.name)
            if extracted_text.startswith("Error"):
                st.error(extracted_text)
                continue
            st.text_area(f"Extracted Text ({uploaded_file.name})", extracted_text, height=200)

            # Step 2: Classify Document
            doc_type = classify_document(extracted_text)
            if doc_type.startswith("Error"):
                st.error(doc_type)
                continue
            st.write(f"**Document Type ({uploaded_file.name})**: {doc_type}")

            # Step 3: Summarize Document
            summary = summarize_text(extracted_text)
            if summary.startswith("Error"):
                st.error(summary)
                continue
            st.write(f"**Summary ({uploaded_file.name})**: {summary}")

            # Save Results
            results.append((uploaded_file.name, extracted_text, doc_type, summary))

        # Bulk Download
        if st.button("Download Results"):
            zip_buffer = BytesIO()
            with ZipFile(zip_buffer, "w") as zf:
                for result in results:
                    file_name, text, doc_type, summary = result
                    zf.writestr(f"{file_name}_summary.txt", f"Document Type: {doc_type}\n\nSummary:\n{summary}")
                    zf.writestr(f"{file_name}_text.txt", text)
            st.download_button("Download All Results as ZIP", zip_buffer.getvalue(), "results.zip")

# Run Streamlit App
if __name__ == "__main__":
    main()

!streamlit run app.py & npx localtunnel --port 8501